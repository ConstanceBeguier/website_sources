<h1>Hidden Markov Models</h1>

<br>

<h4>Définitions</h4>

<p><b>Modèle de Markov:</b>
<ul>
	<li>Le système est dans un état à chaque instant</li>
	<li>Le temps est discret</li>
	<li>Matrice de transition: \(a_{i,j}\): probabilité d'être dans l'état \(j\) sachant que nous étions dans l'état \(i\) à l'étape précédente</li>
	<li>Matrice d'émission: \(b_{i,k}\): probabilité d'observer \(k\) sachant que nous sommes dans l'état \(i\)</li>
</ul></p>

<p>Dans un HMM, les états ne sont pas observables, seulement les observations/émissions sont observables.</p>

<p>Trois problème pour les HMMs:
<ul>
	<li><b>Problème 1</b>: Quelle est la probabilité d'une séquence d'observations donnée ?</li>
	<li><b>Problème 2</b>: Quelle est la séquence d'états la plus probable étant donné une séquence d'observations ?</li>
	<li><b>Problème 3</b>: Comment estimer la matrice de transition \(A\) et la matrice d'émission \(B\) à partir de plusieurs séquences d'observations ?</li>
</ul></p>

<p>Dans les problèmes 1 et 2, nous connaissons \(A\) et \(B\).</p>

<br>

<h4>Forward and backward algorithm (problème 1)</h4>

<p><b>Forward algorithm</b>
<ul>
	<li><b>Idée</b>: calculer \(\alpha _{s,t}\) : probabilité d'être dans l'état \(s\) à \(t\) et d'avoir observé \(o_{1}, o_{2}, ..., o_{t}\)</li>
	<li><b>Algorithme</b>:</li>
	<ul>
		<li>Initialilsation: \(\alpha _{s,1} = b_{s,o_{1}} \pi _{s}\) avec \(\pi_{s}\) la probabilité de partir de l'état \(s\)</li>
		<li>Récursion: \(\alpha _{s,t} = b_{s,o_{t}} \sum_{i} a_{i,s} \alpha _{i,t-1}\)</li>
		<li>Terminaison: \(P(o_{1},...,o_{T}|A,B) = \sum_{i} \alpha _{i,T}\)</li>
	</ul>
</ul></p>

<p><b>Backward algorithm</b></p>

<p>C'est un algorithme alternatif calculant à partir de la fin de la séquence.</p>

<p>\(\beta _{s,t}\): probabilité d'être dans l'état \(s\) à \(t\) et d'observer par la suite \(o_{t+1}, o_{t+2},..., o_{T}\)</p>

<br>

<h4>Viterbi algorithm (problème 2)</h4>

<p><ul>
	<li><b>Idée</b>: calculer \(v_{s,t}\): probabilité du chemin le plus probable qui se termine à l'état \(s\) à \(t\)</li>
	<li><b>Algorithme</b>:</li>
	<ul>
		<li>Initialisation: \(v_{s,1} = b_{s,o_{1}} \pi _{s}\)</li>
		<li>Forward calculs: \(v_{s,t} = b_{s,o_{t}} max_{i} v_{i,t-1} a_{i,s}\)</li>
		<li>Backward calculs: Suivre le chemin ayant le plus grand \(v_{s,T}\)</li>
	</ul>
</ul></p>

<br>

<h4>Baum Welch Algorithm (problème 3)</h4>

<p><ul>
	<li><b>Principe</b>: Expectation-Maximization (EM) méthode pour adapter les paramètres du modèle \((a_{i,j},b_{i,k})\) à partir d'un grand nombre de séquences d'observations \((o_{1},o_{2},...,o_{T})\)</li>
	<ul>
		<li>Expectation: Utiliser alternativement les algorithmes forward et backward pour estimer les probabilités de transitions et d'émissions</li>
		<li>Maximization: Utiliser ces transitions et émissions pour mettre à jour le modèle</li>
	</ul>
	<li><b>Idée</b>: calculer \(\gamma _{i,j,t}\): probabilité qu'à \(t\) nous suivons la transition de \(i\) à \(j\): \(\gamma _{i,j,t} = \frac{\alpha _{i,t} a_{i,j} b_{j,o_{t+1}} \beta_{j,t+1}}{\sum_{i,j} \alpha _{i,t} a_{i,j} b_{i,o_{k}} \beta_{j,t+1}}\)</li>
	<li><b>Mise à jour des paramètres</b>:
$$a_{i,j} = \frac{\sum_{t} \gamma _{i,j,t}}{\sum_{t,m} \gamma _{i,m,t}}$$
$$b_{i,k} = \frac{\sum_{t,o_{t}=k} \sum_{m} \gamma _{i,m,t}}{\sum_{t,m} \gamma _{i,m,t}}$$</li>
</ul></p>

