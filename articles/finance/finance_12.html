<h1>Quelques rappels de statistiques</h1>

<h4>Les statistiques</h4>

<p><b>Variable discrète:</b> \(X(\Omega) = \{x_1, x_2, ..., x_k, ... \}\)
<ul>
	<li> \(P(a \le X \le b) = \sum_{a \le x_k \le b} P(X=x_k)\)</li>
	<li><b>Fonction de répartition:</b> \(F(x) = P(X \le x) = \sum_{x_k \le b} P(X = x_k)\)</li>
	<li><b>Espérance (expectation):</b> \(E[X] = \sum x_k P(X=x_k)\) (similaire à une moyenne pondérée par les probabilités)</li>
	<li>\(E[g(X)] = \sum g(X_k) P(X=x_k)\)</li>
	<li><b>Variance:</b> \(Var(X) = E[X - E[X]]^2\) (mesure de dispersion)</li>
	<li><b>Ecart type (standard deviation std):</b> \(\sigma = \sqrt{Var(X)}\)</li>
	<li><b>Covariance:</b> \(Cov(X,Y)=E[(X-E[X])(Y-E[Y])]\). Si \(X\) et \(Y\) sont indépendantes, \(Cov(X, Y) = 0\).</li>
</ul>
</p>

<p><b>Variable continue à densité \(f\):</b> \(X(\Omega) \in \mathbb{R}\)
<ul>
	<li>\(P(a \le X \le b) = \int_{a}^{b} f(t) dt\)</li>
	<li><b>Fonction de répartition:</b> \(F(x) = P(X \le x) = \int_{-\infty}^{x} f(t) dt\)</li>
	<li><b>Espérance (expectation):</b> \(E[X] = \int_{-\infty}^{\infty} t \cdot f(t) dt\) (similaire à une moyenne pondérée par les probabilités)</li>
	<li>\(E[g(X)] = \int{-\infty}^{\infty} g(t) f(t) dt\)</li>
	<li><b>Variance:</b> \(Var(X) = E[X - E[X]]^2\) (mesure de dispersion)</li>
	<li><b>Ecart type (standard deviation std):</b> \(\sigma = \sqrt{Var(X)}\)</li>
	<li><b>Covariance:</b> \(Cov(X,Y)=E[(X-E[X])(Y-E[Y])]\). Si \(X\) et \(Y\) sont indépendantes, \(Cov(X, Y) = 0\).</li>
</ul>
</p>

<h4>Loi normale</h4>

<p>La <b>loi normale</b> est une des lois de probabilités les plus adaptées pour modéliser des phénomènes aléatoires. Sa densité de probabilité est

$$ f(x) = \frac{1}{\sigma \sqrt{2 \pi}} exp( \frac{-(x - \mu)^2}{\sigma^2})$$

avec \(\mu\) son espérance et \(\sigma\) son écart-type.</p>

<div class="text-center">
<img src="../../img/finance/loi_normale_densite.png" class="img-fluid" alt="loi_normale_densite">
</div>

<p>La <b>loi normale centrée réduite</b> est la loi normale d'espérance nulle et d'écart-type égal à 1.</p>

<p>Lorsqu'une variable aléatoire \(X\) suit une loi normale, nous noterons par la suite \(X \sim (\mu, \sigma)\)</p>

<p>Le <b>théorème central limite</b> établit la convergence en loi de la somme d'une suite de variables aléatoires vers la loi normale.</p>

<p><b>Quelques intervalles de confiance pour la loi normale:</b>

$$P(\mu - \sigma \le x \le \mu + \sigma) \approx 0.6827$$
</p>

<div class="text-center">
<img src="../../img/finance/loi_normale_distribution.png" class="img-fluid" alt="lloi_normale_distribution">
</div>


<h4>Loi log-normale</h4>

<p>Un variable aléatoire \(X\) suit une <b>loi log-normale</b> \((\mu, \sigma)\) si \(Y = ln(X)\) suit une loi normale \((\mu, \sigma)\). La densité de probabilité de \(X\) est

$$f(x) = \left\{ \begin{array}{ll} \frac{1}{x \sigma \sqrt{2 \pi}} exp( \frac{-(ln(x)-\mu)^2}{2 \sigma^2}) & \text{ si } x>0 \\ 0 & \text{ sinon } \end{array} \right.$$
</p>

<div class="text-center">
<img src="../../img/finance/loi_log_normale_densite.png" class="img-fluid" alt="loi_log_normale_densite">
</div>

<p><b>Espérance d'une loi log-normale:</b>
$$E[X] =  e^{\mu + \sigma^2 / 2}$$
</p>

<p><b>Variance d'une loi log-normale:</b>
$$Var(X) = (e^{\sigma^2} - 1) e^{2 \mu + \sigma^2}$$
</p>