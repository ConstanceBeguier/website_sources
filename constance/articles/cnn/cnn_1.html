<h1>Perceptron et MLP</h1>

<p>Nous allons commencer par présenter le <b>perceptron</b> qui est le réseau de neurones le plus simple. Il permet uniquement de classifier des problèmes linéairement séparables. Puis nous allons présenter le <b>multilayer perceptron MLP</b> qui permet de classifier des problèmes non linéairement séparables.</p>

<br>

<h4>Le perceptron</h4>

<p>Le <b>perceptron</b> est un algorithme d'apprentissage supervisé à deux classes. Il permet uniquement de classifier des données linéairement séparables. Il prend en entrée une donnée \(X=(x_1, ..., x_n)^T \in \mathbb{R}^n\) pour en déterminer sa classe \(y \in \{0, 1\}\). En dimension 2, le perceptron consiste en une droite qui sépare l'espace en deux domaines. Si un point est au-dessus de la droite alors il a pour classe 1 et sinon il a pour classe 0. Le perceptron peut par exemple être utilisé pour définir si un mail est un spam ou pas.</p>

<p>Mathématiquement, le perceptron est défini par ses <b>poids</b> \(W=(w_1, ..., w_n)^T \in \mathbb{R}^n\) et son <b>biais/seuil</b> \(b \in \mathbb{R}\). Nous notons \(h_{W,b}(X) = W^T X + b\) la fonction représentant le perceptron. Pour déterminer la classe de sortie sur une nouvelle entrée \(X\), il faut calculer \(h_{W,b}(X)\). Si nous obtenons un nombre supérieur ou égal à 0, la classe de sortie est 1, sinon la classe de sortie est 0.</p>

<div class="text-center">
<img src="../../img/machinelearning/perceptron.jpg" class="img-fluid" alt="perceptron">
</div>

<p>Le biais \(b\) peut être intégré au vecteur \(W\). Pour cela, une coordonnée égale à 1 est ajoutée à chaque vecteur d'entrée \(X\) et son poids associé \(w_0\) est ajouté au vecteur \(W\). Nous avons alors \(h_{W}(X) = W^T X\) et la sortie du perceptron est égale à 0 si \(h_{W}(X)<0\) et 1 si \(h_{W}(X) \geq 0\). </p>

<div class="text-center">
<img src="../../img/machinelearning/perceptron_no_bias.jpg" class="img-fluid" alt="perceptron_no_bias">
</div>

<p>Supposons que nous avons une base de données d'apprentissage contenant des couples \((X,y)\) avec \(X \in \mathbb{R}^n\) la donnée et \(y \in \{0,1\}\) la classe. L'objectif de l'apprentissage est de trouver \(W \in \mathbb{R}^n\) tel que pour tous les couples \((X, y)\), nous avons \(h_{W}(X) \geq 0\) si \(y=1\) et \(h_{W}(X) < 0\) si \(y=0\). A chaque étape de l'apprentissage, un nouveau couple \((X, y)\) de la base de données est utilisé afin d'améliorer les paramètres du perceptron. Analysons si nous devons augmenter ou réduire le poids \(w_k\). Si le perceptron actuel classifie correctement la donnée \(X\) alors il n'est pas nécessaire de modifier les poids. Si \(x_k\) est positif et si le perceptron actuel classifie la donnée en 0 mais que la classe est égale à 1, alors le poids \(w_k\) du perceptron est trop petit. Si \(x_k\) est positif et si le perceptron actuel classifie la donnée en 1 mais que la classe est égale à 0, alors le poids \(w_k\) du perceptron est trop grand. Au contraire si \(x_k\) est négatif et si le perceptron actuel classifie la donnée en 0 mais que la classe est égale à 1, alors le poids \(w_k\) du perceptron est trop grand. Si \(x_k\) est négatif et si le perceptron actuel classifie la donnée en 1 mais que la classe est égale à 0, alors le poids \(w_k\) du perceptron est trop petit. Par conséquent, les nouveaux poids du perceptron peuvent être définis par \(w_k \leftarrow w_k - (s - y)x_k\) avec 
\(s = \begin{cases} 0 & \text{ si } h_{W}(X)<0 \\ 1 & \text{ si } h_{W}(X) \geq 0 \end{cases}\). Habituellement un paramètre \(\alpha\) appelé <b>learning rate</b> est introduit pour ajuster la vitesse d'apprentissage. Les nouveaux poids sont calculés ainsi \(w_k \leftarrow w_k - \alpha(s - y)x_k\).</p>

<table class="table table-bordered">
  <thead>
    <tr>
      <td>y</td>
      <td>s</td>
      <td>\(x_k \geq 0\)</td>
      <td>\(x_k < 0\)</td>
    </tr>
  </thead>
  <tbody>
    <tr>
      <td>1</td>
      <td>0</td>
      <td>\(w_k\) trop petit</td>
      <td>\(w_k\) trop grand</td>
    </tr>
    <tr>
      <td>0</td>
      <td>1</td>
      <td>\(w_k\) trop grand</td>
      <td>\(w_k\) trop petit</td>
    </tr>
  </tbody>
</table>


<p>Il existe différentes <b>astuces</b> pour améliorer ou accélérer l'apprentissage. On peut normaliser les entrées afin d'avoir une moyenne à zéro et une variance à 1 sur chaque coordonnée. On peut réduire le bruit sur les données en entrées avant de commencer l'apprentissage (par exemple, en effectuant une réduction de dimension).</p>

<br>

<h4>Multi-Layer Perceptron  MLP</h4>

<p>Afin de résoudre des problèmes non linéairement séparables, le <b>multi-layer perceptron</b> peut être utilisé. C'est une combinaison de plusieurs perceptrons en série et en parallèle. Afin de résoudre des problèmes non linéairement séparables, une fonction non linéaire appelée <b>fonction d'activation</b> est utilisée. Les fonctions d'activation les plus utilisées sont la <b>ReLU</b> \(f(x) = \max(0,x)\) ou la <b>sigmoid</b> \(f(x) = (1 + e^{-x})^{-1}\). Cette fonction d'activation est appliquée à la sortie de chaque perceptron  \(f(W^T X + b)\) à la place de la comparaison à 0.</p>

<div class="text-center">
<img src="../../img/machinelearning/MLP.jpg" class="img-fluid" alt="mlp">
</div>

<p>La dernière couche contient autant de neurones que de classes. Par exemple, si nous voulons reconnaître les chiffres de 0 à 9, la dernière couche contient 10 classes. L'indice du neurone le plus grand de la dernière couche indique la catégorie/classe de sortie. Afin d'interpréter les neurones de sortie par des probabilités, la fonction <b>softmax</b> est souvent ajoutée après la dernière couche: \(f(x_i) = \frac{e^{x_i}}{\sum _j e^{x_j}}\). Avec la fonction softmax, l'erreur est généralement calculée à l'aide de la <b>cross-entropy</b> : \(- \sum_k y_k \cdot ln(f(x_k))\).</p>

<p>Pour la plupart des problèmes, deux couches cachées suffisent amplement car nous pouvons approximer toutes les fonctions lisses (smooth) par un réseau à deux couches cachées. Le nombre de neurones par couches s'obtient par expérimentation. Il est conseillé de faire une dizaine d'apprentissages par architecture et faire la moyenne des performances obtenues afin de ne pas se tromper à cause d'une initialisation des poids chanceuse. Il est souvent nécessaire d'avoir au moins 10 fois plus de données que de poids dans le réseau à apprendre.</p>

<p>On peut facilement démontrer que le MLP permet d'apprendre tout type de fonctions pouvant être représentées par un circuit booléen. On rappelle que dans l'<b>algèbre de Boole</b>, toute table de vérité (et donc toute fonction logique) peut se décrire à l'aide uniquement des trois types de portes suivantes:
<ul>
	<li>ET (AND)</li>
	<li>OU (OR)</li>
	<li>NON (NOT)</li>
</ul></p>

<p>Par conséquent, si nous pouvons représenter chacune de ces portes à l'aide d'un perceptron, alors un MLP pourra représenter toute fonction logique. Ci-dessous un exemple de représentation par un perceptron de chacune de ces portes. Pour la porte NON, on constate que si l'entrée \(x_1\) est égale à 0 alors \(s\) est égal à \(0,5 + 0 = 0,5\) et \(y\) est donc égal à \(1\). Et si l'entrée \(x_1\) est égale à 1 alors \(s\) est égal à \(0,5 - 1 = -0,5\) et \(y\) est donc égal à \(0\) </p>

<div class="text-center">
<img src="../../img/cnn/perceptron_and.jpg" class="img-fluid" alt="perceptron_and">
</div>

<div class="text-center">
<img src="../../img/cnn/perceptron_or.jpg" class="img-fluid" alt="perceptron_or">
</div>

<div class="text-center">
<img src="../../img/cnn/perceptron_not.jpg" class="img-fluid" alt="perceptron_not">
</div>

