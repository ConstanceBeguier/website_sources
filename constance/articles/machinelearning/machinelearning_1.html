<h1>Un peu de maths</h1>

<br>

<h4>La descente de gradient</h4>

<p>La descente de gradient permet de trouver efficacement un minimum local d'une fonction à plusieurs variables. Supposons que notre fonction représente la surface d'une chaine de montagnes. Le principle consiste à partir d'un point aléatoire sur cette chaine de montagnes. A chaque étape, il faut analyser la pente tout autour de soi et descendre d'un pas dans la direction de la pente la plus importante. Lorsque nous ne pouvons plus descendre, nous avons atteint un minimum local de la fonction.</p>

<p>Mathématiquement, nous notons f(x, y) la fonction représentant la surface de notre chaine de montagnes. Trouver la direction de la pente la plus importante correspond à calculer les dérivées partielles \(\frac{\partial f}{\partial x}\) et \(\frac{\partial f}{\partial y}\). C'est le gradient de notre fonction \(\nabla f = (\frac{\partial f}{\partial x}, \frac{\partial f}{\partial y})\). Si nous sommes en position \(x_0, y_0\), la nouvelle position après avoir descendu d'un pas dans la direction de la pente la plus élevée est \((x_0,y_0) - \alpha \nabla f(x_0,y_0)\) avec \(\alpha\) la longueur du pas appelé learning rate.</p>

<p>Le learning rate utilisé pendant la descente de gradient n'est pas forcément constant. Il est conseillé d'en choisir un qui diminue au cours des itérations afin de faire des grands pas au début de la descente et des petits pas à la fin. L'exponential  decay est couramment utilisé : \(\alpha = \alpha _0 \cdot e^{-kt}\) où \(t\) est le nombre d'itérations, \(\alpha_0\) est le learning rate initial et \(k\) un paramètre.</p>

<p>La méthode de la descente de gradient est souvent utilisée lors des apprentissages. Le principe est de créer une fonction d'erreur qui permet d'évaluer les performances de notre algorithme d'apprentissage. Puis d'effectuer une descente de gradient sur cette fonction d'erreur afin de trouver les paramètres de la fonction qui minimisent l'erreur.</p>


<br>

<h4>Quelques rappels de probabilité</h4>

<p><b>Bayes’ rule :</b> \(P (C_i |X_j ) = \frac{P(X_j | C_i) \cdot P(C_i)}{P(X_j)}\) car \(P(X_j |C_i ) = P (X_j , C_i )/P (C_i )\)</p>

<p><b>Posterior probability:</b> \(P (C_i |X_j )\)</p>

<p><b>Prior probability:</b> \(P (C_i )\)</p>

<p><b>Class conditionnal probability:</b> \(P (X_j |C_i )\)</p>

<p><b>Maximum a posteriori (MAP):</b> \(argmax_i P(C_i |X)\) : quelle est la classe la plus probable pour une entrée donnée (vecteur de features)</p>

<p><b>Naive Bayes’ Classifier:</b> MAP en supposant que les features sont indépendantes entre elles. Donc \(P(X|C_i ) = \prod_j P(X_j |C_i )\). Et donc \(argmax_i P(C_i | X) = argmax_i P(C_i)\) et \(\prod_j P(X_j | C_i) / P(X) = argmax_i  P(C_i) \prod_j P(X_j | C_i)\)</p>

<br>

<h4>Quelques rappels de statistiques</h4>

<p><b>Espérance (expectation) :</b> similaire à une moyenne en prenant en compte les probabilités : \(E[f (X)] = \sum_i f (X_i ) \cdot P (X_i )\)</p>

<p><b>Variance :</b> mesure de dispersion : \(var(X) = E[X-E[X]]^2 = E[X - \mu]^2\) où \(\mu\) est la moyenne/espérance de \(X\)</p>

<p><b>Ecart type (standard deviation std) :</b> \(\sigma = \sqrt{var(X)}\)</p>

<p><b>Covariance :</b> \(cov(X,Y)=E[(X-E[X])(Y-E[Y])]\). Si \(X\) et \(Y\) sont indépendantes, \(cov(X, Y ) = 0\).</p>

<p><b>Gaussienne ou distribution normale :</b> \(p(x) = \frac{1}{\sqrt{2 \pi \sigma}} exp( \frac{-(x-\mu)^2}{2 \sigma^2})\)</p>

<p><b>Central Limit Theorem :</b> convergence en loi de la somme d’une suite de variables aléatoires vers la loi normale</p>
